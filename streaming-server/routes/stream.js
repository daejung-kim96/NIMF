// stream.js
// streaming ê´€ë ¨ API ë¼ìš°í„° ì •ì˜
// Author: Junghyun Park
// Date: 2025-08-07

// TODO(Junghyun Park, 2025-08-08): webRTCë¡œ ë°›ì€ ì˜ìƒ ì†¡ì¶œ start router í•„ìš”

const express = require('express');
const { spawn } = require('child_process');
const os = require('os');
const router = express.Router();
const path = require('path');
const {
  RTCPeerConnection,
  nonstandard: { RTCAudioSink, RTCVideoSink },
} = require('wrtc');

const { handleStream } = require('../socket/stream-handler');
const { sessionToStream } = require('../socket/handler');

const isWindows = os.platform() === 'win32';

const ffmpegPath = isWindows ? path.resolve(__dirname, '../bin/ffmpeg.exe') : 'ffmpeg'; // ffmpegë¥¼ ì„œë²„ì— ë‹¤ìš´ë°›ì§€ ì•Šì•„ë„ exeë¡œ êµ´ëŸ¬ê°, linuxì˜ ê²½ìš° ë‹¬ë¼ì ¸ì•¼í•¨

// const ffmpegProcess = spawn(ffmpegPath, [...]);
let ffmpegProcess = null;
const sessions = new Map(); // sessionId -> { pc, audioSink, videoSink, ffmpeg }

router.post('/start', (req, res) => {
  const { sessionId, streamKey, platform } = req.body;
  console.log('ðŸ§ª ë“±ë¡ëœ ì„¸ì…˜ ëª©ë¡:', [...sessionToStream.keys()]);
  if (!sessionId) return res.status(400).json({ success: false, message: 'sessionId is required' });
  if (!streamKey) return res.status(400).json({ success: false, message: 'streamKey is required' });

  console.log(`ðŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘ ìš”ì²­: ${sessionId}, ${platform || 'youtube'}`);

  const result = handleStream(sessionId, streamKey, platform || 'youtube');

  if (result.success) {
    res.json({ success: true, message: result.message });
  } else {
    res.status(400).json({ success: false, message: result.message });
  }
});

// --- POST / stop ---
module.exports = router;

// --- WebRTC ìˆ˜ì‹  â†’ FFmpeg íŒŒì´í”„ â†’ RTMP ì†¡ì¶œ ---
// router.post('/webrtc/init', async (req, res) => {
//   const { streamKey, sessionId } = req.body || {};
//   if (!streamKey) return res.status(400).json({ error: 'streamKey is required' });
//   if (!sessionId) return res.status(400).json({ error: 'sessionId is required' });

//   // ê¸°ì¡´ ì„¸ì…˜ì´ ì¡´ìž¬í•˜ë©´ ì •ë¦¬ í›„ ìž¬ìˆ˜ë¦½
//   const existing = sessions.get(sessionId);
//   if (existing) {
//     console.log(`[webrtc][${sessionId}] existing session detected. Recycling...`);
//     try { existing.pc && existing.pc.close(); } catch {}
//     try { existing.ffmpeg && existing.ffmpeg.kill('SIGINT'); } catch {}
//     sessions.delete(sessionId);
//   }

//   const rtmpUrl = `rtmp://a.rtmp.youtube.com/live2/${streamKey}`;

//   // 1) FFmpeg í”„ë¡œì„¸ìŠ¤ ìƒì„± (stdinìœ¼ë¡œ raw frames ìž…ë ¥)
//   const args = [
//     '-y',
//     // ë¹„ë””ì˜¤ ìž…ë ¥ (raw I420)
//     '-f', 'rawvideo',
//     '-pix_fmt', 'yuv420p',
//     '-s', '1280x720',
//     '-r', '30',
//     '-i', 'pipe:3',
//     // ì˜¤ë””ì˜¤ ìž…ë ¥ (s16le)
//     '-f', 's16le',
//     '-ar', '48000',
//     '-ac', '1',
//     '-i', 'pipe:4',
//     // ì €ì§€ì—° ì¸ì½”ë”© ì˜µì…˜
//     '-c:v', 'libx264',
//     '-preset', 'ultrafast',  // veryfast -> ultrafastë¡œ ë³€ê²½
//     '-tune', 'zerolatency',   // ì§€ì—° ìµœì†Œí™”
//     '-pix_fmt', 'yuv420p',
//     '-g', '30',              // GOP í¬ê¸° ì¤„ìž„ (60 -> 30)
//     '-keyint_min', '30',     // ìµœì†Œ í‚¤í”„ë ˆìž„ ê°„ê²©
//     '-sc_threshold', '0',    // ìž¥ë©´ ë³€í™” ê°ì§€ ë¹„í™œì„±í™”
//     '-bufsize', '512k',      // ë²„í¼ í¬ê¸° ìµœì†Œí™”
//     '-maxrate', '2500k',     // ìµœëŒ€ ë¹„íŠ¸ë ˆì´íŠ¸ ì œí•œ
//     '-b:v', '2000k',         // ë¹„ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸ ê³ ì •
//     '-vsync', 'cfr',         // Constant Frame Rate ê°•ì œ
//     '-c:a', 'aac', '-b:a', '128k', '-ar', '48000',
//     '-f', 'flv', rtmpUrl
//   ];

//   const ff = spawn(ffmpegPath, args, { stdio: ['ignore', 'pipe', 'pipe', 'pipe', 'pipe'] });
//   ff.stdout.on('data', (d) => console.log(`[ffmpeg stdout][${sessionId}] ${d}`));
//   ff.stderr.on('data', (d) => console.error(`[ffmpeg stderr][${sessionId}] ${d}`));
//   ff.on('close', (code) => {
//     console.log(`[ffmpeg][${sessionId}] exited with code ${code}`);
//     const sess = sessions.get(sessionId);
//   });

//   // 2) WebRTC PeerConnection ìƒì„± (ì˜ìƒ/ìŒì„± ìˆ˜ì‹ )
//   const pc = new RTCPeerConnection({});

//   // --- WebRTC ìƒíƒœ ë¡œê¹… ---
//   const logPrefix = `[webrtc][${sessionId}]`;
//   pc.onconnectionstatechange = () => {
//     console.log(`${logPrefix} connection: ${pc.connectionState} | ICE: ${pc.iceConnectionState} | Gathering: ${pc.iceGatheringState}`);
//     if (pc.connectionState === 'failed') {
//       console.error(`${logPrefix} connection failed`);
//     }
//     if (pc.connectionState === 'closed' || pc.connectionState === 'failed') {
//       const sess = sessions.get(sessionId);
//     }
//   };
//   pc.oniceconnectionstatechange = () => {
//     console.log(`${logPrefix} ICE connection state: ${pc.iceConnectionState}`);
//   };
//   pc.onicegatheringstatechange = () => {
//     console.log(`${logPrefix} ICE gathering state: ${pc.iceGatheringState}`);
//   };
//   pc.onicecandidate = (event) => {
//     const hasCandidate = !!(event && event.candidate);
//     console.log(`${logPrefix} ICE candidate: ${hasCandidate ? 'received' : 'null (end)'}`);
//   };

//   // ê° íŠ¸ëž™ì— ëŒ€í•´ Sink ìƒì„±í•˜ì—¬ raw frameì„ ffmpeg stdinìœ¼ë¡œ ì „ë‹¬
//   let videoSink = null;
//   let audioSink = null;

//   // ì„¸ì…˜ ì´ˆê¸° ì—”íŠ¸ë¦¬ ì¤€ë¹„ (í‹°ì»¤/ë²„í¼ í¬í•¨)
//   sessions.set(sessionId, {
//     pc,
//     audioSink: null,
//     videoSink: null,
//     ffmpeg: ff,
//   });

//   pc.ontrack = (event) => {
//     const [track] = event.streams.length ? event.streams[0].getTracks() : [event.track];
//     const kind = event.track.kind;
//     console.log(`ðŸ“¥ [${sessionId}] track received: ${kind}`);

//     if (kind === 'video') {
//       videoSink = new RTCVideoSink(event.track);
//       const targetFps = 30;  // FFmpegì™€ ë™ì¼í•˜ê²Œ 30fpsë¡œ ì„¤ì •
//       const intervalMs = Math.floor(1000 / targetFps);  // 33.33ms

//       let frameCounter = 0;
//       let lastWriteTime = Date.now();

//       videoSink.onframe = ({ frame }) => {
//         try {
//           const sess = sessions.get(sessionId);
//           if (!sess) return;

//           // Otherwise, compose from planes (y/u/v) with stride
//           const { width, height } = frame || {};
//           const y = frame && (frame.y || frame.Y || frame.planeY);
//           const u = frame && (frame.u || frame.U || frame.planeU);
//           const v = frame && (frame.v || frame.V || frame.planeV);
//           const strideY = frame && (frame.strideY || frame.stride || frame.linesizeY || width);
//           const strideU = frame && (frame.strideU || frame.linesizeU || Math.floor(width / 2));
//           const strideV = frame && (frame.strideV || frame.linesizeV || Math.floor(width / 2));

//           if (!width || !height || !y || !u || !v) {
//             throw new Error('Unsupported frame format from wrtc');
//           }

//           const ySize = width * height;
//           const uvWidth = Math.floor(width / 2);
//           const uvHeight = Math.floor(height / 2);
//           const uSize = uvWidth * uvHeight;
//           const vSize = uvWidth * uvHeight;

//           const out = Buffer.allocUnsafe(ySize + uSize + vSize);
//           // Copy Y plane
//           for (let row = 0; row < height; row++) {
//             const srcStart = row * strideY;
//             const dstStart = row * width;
//             const rowSlice = y.subarray ? y.subarray(srcStart, srcStart + width) : y.slice(srcStart, srcStart + width);
//             out.set(rowSlice, dstStart);
//           }
//           // Copy U plane
//           let offset = ySize;
//           for (let row = 0; row < uvHeight; row++) {
//             const srcStart = row * strideU;
//             const rowSlice = u.subarray ? u.subarray(srcStart, srcStart + uvWidth) : u.slice(srcStart, srcStart + uvWidth);
//             out.set(rowSlice, offset + row * uvWidth);
//           }
//           // Copy V plane
//           offset = ySize + uSize;
//           for (let row = 0; row < uvHeight; row++) {
//             const srcStart = row * strideV;
//             const rowSlice = v.subarray ? v.subarray(srcStart, srcStart + uvWidth) : v.slice(srcStart, srcStart + uvWidth);
//             out.set(rowSlice, offset + row * uvWidth);
//           }
//         } catch (e) {
//           console.error(`[${sessionId}] video frame process error:`, e);
//         }
//       };
//     } else if (kind === 'audio') {
//       audioSink = new RTCAudioSink(event.track);
//       audioSink.ondata = ({ samples }) => {
//         try {
//           const buf = samples.buffer || samples.data;
//           if (buf) {
//             ff.stdio[4].write(Buffer.from(buf));
//           }
//         } catch (e) {
//           console.error(`[${sessionId}] audio write error:`, e);
//         }
//       };
//     }
//   };

//   const offer = await pc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: true });
//   await pc.setLocalDescription(offer);

//   // ì„¸ì…˜ ì—”íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
//   const sess0 = sessions.get(sessionId) || {};
//   sessions.set(sessionId, { ...sess0, pc, audioSink, videoSink, ffmpeg: ff });

//   return res.json({ offer: { type: offer.type, sdp: offer.sdp } });
// });

// router.post('/webrtc/answer', async (req, res) => {
//   const { sessionId, answer } = req.body || {};
//   const sess = sessions.get(sessionId);
//   if (!sess) return res.status(404).json({ error: 'session not found' });

//   try {
//     await sess.pc.setRemoteDescription(answer);
//     return res.json({ status: 'ok' });
//   } catch (e) {
//     console.error('setRemoteDescription error:', e);
//     return res.status(500).json({ error: String(e) });
//   }
// });

router.post('/stop', (req, res) => {
  const { sessionId } = req.body;

  console.log(`ðŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ìš”ì²­: ${sessionId}`);

  const streamInfo = sessionToStream.get(sessionId);

  // 1. streamInfo ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
  if (!streamInfo) {
    console.log(`âš ï¸ ì„¸ì…˜ ì •ë³´ ì—†ìŒ: ${sessionId}`);
    return res.status(400).send('ì„¸ì…˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ');
  }

  // 2. FFmpeg í”„ë¡œì„¸ìŠ¤ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
  if (!streamInfo.ffmpegProcess) {
    console.log(`âš ï¸ FFmpeg í”„ë¡œì„¸ìŠ¤ ì—†ìŒ: ${sessionId}`);
    return res.status(400).send('ì†¡ì¶œ ì¤‘ì´ ì•„ë‹˜');
  }

  // 3. ì´ë¯¸ ì¢…ë£Œëœ í”„ë¡œì„¸ìŠ¤ì¸ì§€ í™•ì¸
  if (streamInfo.ffmpegProcess.killed) {
    console.log(`âš ï¸ FFmpeg í”„ë¡œì„¸ìŠ¤ ì´ë¯¸ ì¢…ë£Œë¨: ${sessionId}`);
    streamInfo.ffmpegProcess = null;
    return res.send('ðŸ›‘ ì†¡ì¶œ ì´ë¯¸ ì¢…ë£Œë¨');
  }

  console.log(`ðŸ›‘ FFmpeg ì¢…ë£Œ ì¤‘: ${sessionId}`);

  // 4. ì •ìƒ ì¢…ë£Œ ì‹œë„
  streamInfo.ffmpegProcess.kill('SIGTERM');

  // 5. ê°•ì œ ì¢…ë£Œ íƒ€ì´ë¨¸ ì„¤ì •
  const forceKillTimer = setTimeout(() => {
    if (streamInfo.ffmpegProcess && !streamInfo.ffmpegProcess.killed) {
      console.log(`ðŸ”´ FFmpeg ê°•ì œ ì¢…ë£Œ: ${sessionId}`);
      streamInfo.ffmpegProcess.kill('SIGKILL');
    }
  }, 5000);

  // 6. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
  streamInfo.ffmpegProcess.once('exit', (code, signal) => {
    console.log(`âœ… FFmpeg ì¢…ë£Œ ì™„ë£Œ: ${sessionId} (ì½”ë“œ: ${code}, ì‹œê·¸ë„: ${signal})`);
    clearTimeout(forceKillTimer); // íƒ€ì´ë¨¸ ì •ë¦¬
    streamInfo.ffmpegProcess = null;
    streamInfo.streamKey = null;
    streamInfo.platform = null;
    streamInfo.isStreaming = false;
  });

  return res.send('ðŸ›‘ ì†¡ì¶œ ì¢…ë£Œ ì¤‘...');
});

router.get('/debug/sessions', (req, res) => {
  const { sessionToStream } = require('../socket/session-store');
  res.json([...sessionToStream.keys()]);
});
