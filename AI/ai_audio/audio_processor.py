
"""
ì˜¤ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ ëª¨ë“ˆ
@module audio_processor
@author HeeGyeong
@date 2025-08-16
@description ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ëŠ” AudioProcessor í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
"""

import queue
import asyncio
import numpy as np
import sys
import os
import json
from aiortc import MediaStreamTrack
from av import AudioFrame
from scipy import signal
import soundfile as sf
from datetime import datetime
import time as pytime

# AI ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (í•œ ë‹¨ê³„ ìœ„ë¡œ)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
# curse_words_severity.json íŒŒì¼ ê²½ë¡œ
curse_file_path = os.path.join(os.path.dirname(__file__), 'data', 'curse_words_severity.json')

from ai_audio.stt_engine import StreamingSpeechRecognizer
from session_state_manager import session_state_manager

# ìš•ì„¤ ìˆ˜ìœ„ í•œê¸€ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
CATEGORY_KOREAN_MAP = {
    'high': 'ìš•ì„¤-ìˆ˜ìœ„ ë†’ìŒ',
    'mid': 'ìš•ì„¤-ìˆ˜ìœ„ ì¤‘ê°„',
    'low': 'ìš•ì„¤-ìˆ˜ìœ„ ë‚®ìŒ'
}

# ìš•ì„¤ í•„í„°ë§ ìˆ˜ì¤€ì— ë”°ë¼ í—ˆìš©ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ë§¤í•‘
PROFANITY_LEVEL_MAPPING = {
    'high': ['high', 'mid', 'low'],
    'mid': ['high', 'mid'],
    'low': ['high'],
}

# ìš•ì„¤ ìˆ˜ìœ„ ìš°ì„ ìˆœìœ„ ë§¤í•‘
PROFANITY_LEVEL_PRIORITY_MAP = {
    'high': 3,
    'mid': 2,
    'low': 1
}


class AudioProcessor(MediaStreamTrack):
    """
    ì˜¤ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ í´ë˜ìŠ¤
    
    í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ì€ ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ê³  ë‹¤ì‹œ ì „ì†¡í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """
    kind = "audio"
    data_channel = None

    def __init__(self, track=None, session_id: str = None):  # â† trackê³¼ session_id ë§¤ê°œë³€ìˆ˜
        """
        AudioProcessor ì´ˆê¸°í™”
        
        @param {MediaStreamTrack} track - ì›ë³¸ ì˜¤ë””ì˜¤ íŠ¸ë™
        @param {str} session_id - ì„¸ì…˜ ID
        """
        super().__init__()
        self.track = track  # â† ì›ë³¸ íŠ¸ë™ ì €ì¥
        self.session_id = session_id  # â† ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        print(f"ğŸ§ AudioProcessor ìƒì„±ë¨ (ì„¸ì…˜: {session_id})")
        
        # ì˜¤ë””ì˜¤ ë²„í¼ë§ ê´€ë ¨
        self.audio_buffer = []
        self.buffer_start_time = None
        self.buffer_sample_rate = None
        self.buffer_channels = 1
        self.buffer_duration = 3.0 # 3ì´ˆ ë²„í¼ë§
        self.target_sample_rate = 16000  # STT ì—”ì§„ ìš”êµ¬ì‚¬í•­
        
        # í”„ë ˆì„ ë¶„ì„ ê´€ë ¨
        self.last_pts = None
        self.expected_pts_increment = None
        self.is_first_frame = True
        self.frame_count = 0
        self.total_frames_received = 0
        self.last_frame_time = None
        self.frame_intervals = []
        self.expected_frame_interval = None
        self.pts_gaps = []
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            'total_frames': 0,
            'processed_frames': 0,
            'processing_time': 0.0,
            'audio_level': 0.0
        }
        
        # ìŒì„± ì¸ì‹ê¸° ì´ˆê¸°í™”
        self.speech_recognizer = None
        self.recognition_results = []
        self._initialize_speech_recognition()

        # ìŠ¤ë ˆë“œ ì•ˆì „í•œ í (asyncioê°€ ì•„ë‹Œ threading í ì‚¬ìš©)
        self.stt_result_queue = queue.Queue()


        # ìš•ì„¤ ë‹¨ì–´ ì‚¬ì „ ë¡œë“œ 
        try:
            curse_file_path = os.path.join(os.path.dirname(__file__), 'data', 'curse_words_severity.json')
            with open(curse_file_path, 'r', encoding='utf-8') as f:
                self.curse_words = json.load(f)
            print(f"âœ… ìš•ì„¤ ë‹¨ì–´ ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {len(self.curse_words)}ê°œ ì¹´í…Œê³ ë¦¬")
        except Exception as e:
            print(f"âŒ ìš•ì„¤ ë‹¨ì–´ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")


    
    def _initialize_speech_recognition(self):
        """
        ìŒì„± ì¸ì‹ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        def on_recognition_result(text: str, timestamp: float):
            """ìŒì„± ì¸ì‹ ê²°ê³¼ ì½œë°±"""
            if text.strip():
                self.recognition_results.append(text)
                print(f"ğŸ¯ ìŒì„± ì¸ì‹ ê²°ê³¼: {text}")

                # ğŸ”¥ ìŠ¤ë ˆë“œ ì•ˆì „í•œ íì— ê²°ê³¼ ì¶”ê°€
                try:
                    self.stt_result_queue.put({'text': text, 'timestamp': timestamp}, block=False)
                    print(f"ğŸ“¥ STT ê²°ê³¼ íì— ì¶”ê°€ë¨: {text}")
                except queue.Full:
                    print("âš ï¸ STT ê²°ê³¼ íê°€ ê°€ë“ì°¸")
                except Exception as e:
                    print(f"âŒ STT ê²°ê³¼ í ì¶”ê°€ ì‹¤íŒ¨: {e}")
        
        try:
            self.speech_recognizer = StreamingSpeechRecognizer(
                model_size="small",  
                language="ko",
                on_result=on_recognition_result
            )
            print("âœ… Whisper ìŒì„± ì¸ì‹ê¸°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ìŒì„± ì¸ì‹ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.speech_recognizer = None
    


    def _resample_audio(self, audio_data: np.ndarray, original_rate: int, target_rate: int) -> np.ndarray:
        """
        ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
        
        @param audio_data: ì›ë³¸ ì˜¤ë””ì˜¤ ë°ì´í„°
        @param original_rate: ì›ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸
        @param target_rate: ëª©í‘œ ìƒ˜í”Œë§ ë ˆì´íŠ¸
        @returns: ë¦¬ìƒ˜í”Œë§ëœ ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        if original_rate == target_rate:
            return audio_data
        
        target_length = int(len(audio_data) * target_rate / original_rate)
        resampled_audio = signal.resample(audio_data, target_length)
        
        return resampled_audio.astype(audio_data.dtype)



    async def recv(self):
        """
        ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        @returns {AudioFrame} ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ í”„ë ˆì„
        """
        # STT ê²°ê³¼ ì²˜ë¦¬ (ë…¼ë¸”ë¡œí‚¹)
        self._process_stt_results_sync()
        frame = await self.track.recv()

        try:

            # ====================== ë¡œê¹… ì‹œì‘ ======================

            # 0. í”„ë ˆì„ ì¹´ìš´íŒ… ë° ì‹œê°„ ì¸¡ì •
            self.frame_count += 1
            self.total_frames_received += 1
            current_time = pytime.time()
            
            # 1. í”„ë ˆì„ ê°„ê²© ëª¨ë‹ˆí„°ë§
            if self.last_frame_time is not None:
                interval = current_time - self.last_frame_time
                self.frame_intervals.append(interval)
                
                if len(self.frame_intervals) == 10:
                    self.expected_frame_interval = sum(self.frame_intervals) / len(self.frame_intervals)
                    # print(f"ğŸ“Š ì˜ˆìƒ í”„ë ˆì„ ê°„ê²©: {self.expected_frame_interval*1000:.1f}ms")
                
                if self.total_frames_received % 100 == 0:
                    recent_intervals = self.frame_intervals[-20:]
                    avg_interval = sum(recent_intervals) / len(recent_intervals)
                    max_interval = max(recent_intervals)
                    min_interval = min(recent_intervals)
                    # print(f"ğŸ• í”„ë ˆì„ ê°„ê²© ë¶„ì„ (ìµœê·¼ 20ê°œ): í‰ê· ={avg_interval*1000:.1f}ms, ìµœëŒ€={max_interval*1000:.1f}ms, ìµœì†Œ={min_interval*1000:.1f}ms")
                    
                    if self.expected_frame_interval:
                        long_gaps = [i for i in recent_intervals if i > self.expected_frame_interval * 2]
                        if long_gaps:
                            print(f"âš ï¸ ê¸´ ê°„ê²© ê°ì§€: {len(long_gaps)}ê°œ, ìµœëŒ€ {max(long_gaps)*1000:.1f}ms")
            
            self.last_frame_time = current_time
            
            # ì˜¤ë””ì˜¤ í”„ë ˆì„ì˜ ì›ì‹œ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            audio_data = np.frombuffer(frame.planes[0], dtype=np.int16)
            
            # 2. PTS ë¶„ì„
            if hasattr(frame, 'pts') and frame.pts is not None:
                current_pts = frame.pts
                
                if self.last_pts is not None:
                    pts_diff = current_pts - self.last_pts
                    self.pts_gaps.append(pts_diff)
                    
                    if len(self.pts_gaps) == 10:
                        self.expected_pts_increment = sum(self.pts_gaps) / len(self.pts_gaps)
                        print(f"ğŸ“Š ì˜ˆìƒ PTS ì¦ê°€ëŸ‰: {self.expected_pts_increment}")
                    
                    if self.frame_count % 5000 == 0:
                        recent_gaps = self.pts_gaps[-10:] if len(self.pts_gaps) >= 10 else self.pts_gaps
                        avg_gap = sum(recent_gaps) / len(recent_gaps) if recent_gaps else 0
                        print(f"ğŸ“ˆ PTS: {current_pts}, í‰ê·  ê°­: {avg_gap:.0f}, í”„ë ˆì„ í¬ê¸°: {len(audio_data)}")
                        
                        if self.expected_pts_increment and pts_diff > self.expected_pts_increment * 1.5:
                            missing_duration = (pts_diff - self.expected_pts_increment) / self.expected_pts_increment
                            print(f"âš ï¸ PTS ê°­ ê°ì§€! ì˜ˆìƒ: {self.expected_pts_increment:.0f}, ì‹¤ì œ: {pts_diff:.0f} (ì•½ {missing_duration:.1f}í”„ë ˆì„ ëˆ„ë½)")
                
                self.last_pts = current_pts
            


            # 3. í”„ë ˆì„ ì •ë³´ ë¡œê¹… (ì²« í”„ë ˆì„ì—ì„œë§Œ)
            if self.is_first_frame:
                print(f"ğŸ”Š ì˜¤ë””ì˜¤ ë°ì´í„° í†µê³„: min={audio_data.min()}, max={audio_data.max()}, mean={audio_data.mean():.1f}, rms={np.sqrt(np.mean(audio_data.astype(np.float32)**2)):.1f}")
                # min=-1859, max=1958, mean=33.3, rms=830.3
                print(f"ğŸ” í”„ë ˆì„ í¬ë§·: {frame.format}") # <av.AudioFormat s16>
                print(f"ğŸ” í”„ë ˆì„ ìƒ˜í”Œ ë ˆì´íŠ¸: {frame.sample_rate}Hz") # 48000Hz
                print(f"ğŸ” í”„ë ˆì„ ì±„ë„ ìˆ˜: {frame.layout}") #  <av.AudioLayout 'stereo'>
                print(f"ğŸ” í”„ë ˆì„ ë°ì´í„° í¬ê¸°: {len(audio_data)}") # 1920
                print(f"ğŸ” í”„ë ˆì„ ë°ì´í„° íƒ€ì…: {audio_data.dtype}") # int16
                print(f"ğŸ” í”„ë ˆì„ ë°ì´í„° í˜•íƒœ: {audio_data.shape}") # (1920,)
                print(f"ğŸ” í”„ë ˆì„ ë°ì´í„° í¬ë§·: {frame.format}") #  <av.AudioFormat s16>
                self.is_first_frame = False



            #ë§¤ 125 í”„ë ˆì„ë§ˆë‹¤ = 5ì´ˆ ê°€ëŸ‰
            if self.frame_count % 125 == 0:
                # 4. ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„
                if len(audio_data.shape) > 1:
                    audio_data_1d = audio_data.flatten()
                else:
                    audio_data_1d = audio_data
                    
                rms = np.sqrt(np.mean(audio_data_1d.astype(np.float32) ** 2))
                is_silence = rms < 100
                print(f"ğŸ”Š ì˜¤ë””ì˜¤ ë ˆë²¨: RMS={rms:.1f}, ë¬´ìŒ={'ì˜ˆ' if is_silence else 'ì•„ë‹ˆì˜¤'}")

                # 5. ë²„í¼ë§ ì§„í–‰ ìƒí™©
                elapsed = current_time - self.buffer_start_time
                buffer_samples = len(self.audio_buffer)
                expected_samples = int(self.buffer_sample_rate * elapsed)
                print(f"ğŸ“Š ë²„í¼ë§ ì§„í–‰ [{self.frame_count}í”„ë ˆì„]: {elapsed:.1f}ì´ˆ ê²½ê³¼, ë²„í¼ ìƒ˜í”Œ={buffer_samples}, ì˜ˆìƒ ìƒ˜í”Œ={expected_samples}")

                

            # ====================== ë¡œê¹… ë ======================
 

            # ğŸ”¥ ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜ 
            if hasattr(frame, 'layout') and 'stereo' in str(frame.layout).lower():
                if self.buffer_start_time is None:  # ì²« í”„ë ˆì„ì—ì„œë§Œ ë¡œê·¸
                    print("ğŸ” ìŠ¤í…Œë ˆì˜¤ í”„ë ˆì„ ê°ì§€ë¨ â€“ ëª¨ë…¸ë¡œ ë³€í™˜")
                # ìŠ¤í…Œë ˆì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜
                audio_data = audio_data.reshape(-1, 2).mean(axis=1).astype(np.int16)
            

            # ë²„í¼ ì´ˆê¸°í™” (ì²« í”„ë ˆì„ì—ì„œë§Œ)
            if self.buffer_start_time is None:
                self.buffer_start_time = current_time
                self.buffer_sample_rate = frame.sample_rate
                self.buffer_channels = 1  # ëª¨ë…¸ë¡œ ê³ ì •
                
            self.audio_buffer.extend(audio_data)
        

            # 3ì´ˆ ê²½ê³¼ ì‹œ ë²„í¼ì— ì €ì¥
            if current_time - self.buffer_start_time >= self.buffer_duration:
                print(f"ğŸ‰ 3ì´ˆ ë²„í¼ ì™„ì„±! ê²½ê³¼ì‹œê°„: {current_time - self.buffer_start_time:.2f}ì´ˆ, ë²„í¼ í¬ê¸°: {len(self.audio_buffer)} ìƒ˜í”Œ")
                try:
                    audio_np = np.array(self.audio_buffer[:int(self.buffer_sample_rate * self.buffer_duration)], dtype=np.int16)
                    print(f"ğŸ”¢ numpy ë°°ì—´ ìƒì„±ë¨: {len(audio_np)} ìƒ˜í”Œ, dtype={audio_np.dtype}")

                    # ì •ê·œí™” ê°œì„  (í´ë¦¬í•‘ ë°©ì§€ë§Œ)
                    max_val = np.abs(audio_np).max()
                    if max_val > 32767:  # í´ë¦¬í•‘ì´ ë°œìƒí•  ê²½ìš°ë§Œ
                        audio_np = (audio_np / max_val * 32767 * 0.95).astype(np.int16)
                        print(f"âš ï¸ í´ë¦¬í•‘ ë°©ì§€ ì •ê·œí™”: {max_val} â†’ 32767")


                    # 16kHzë¡œ ë¦¬ìƒ˜í”Œë§ ë° STT ì²˜ë¦¬
                    resampled_audio = self._resample_audio(audio_np, self.buffer_sample_rate, 16000)
                    
                    # float32ë¡œ ì •ê·œí™” (Whisper ìš”êµ¬ì‚¬í•­: -1.0 ~ 1.0 ë²”ìœ„)
                    audio_float = resampled_audio.astype(np.float32) / 32767.0
                    
                    # STT ì—”ì§„ìœ¼ë¡œ ì „ì†¡ (3ì´ˆ ê°„ê²©)                    
                    if self.speech_recognizer and self.speech_recognizer.is_running:
                        try:
                            self.speech_recognizer.process_audio_chunk({'audio_data': audio_float,'timestamp': float(current_time)})
                        except Exception as e:
                            print(f"âŒ STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            print(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                            import traceback
                            print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                    else:
                        print("âš ï¸ STT ì—”ì§„ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
                        if not self.speech_recognizer:
                            print("   â†’ speech_recognizerê°€ Noneì…ë‹ˆë‹¤")
                        elif not self.speech_recognizer.is_running:
                            print("   â†’ speech_recognizer.is_runningì´ Falseì…ë‹ˆë‹¤")

                    # 3ì´ˆ ê°„ê²©ìœ¼ë¡œ ìë¥´ê¸° (ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì—†ì´)
                    self.audio_buffer = []  # ë²„í¼ ì™„ì „íˆ ë¹„ìš°ê¸°
                    self.buffer_start_time += self.buffer_duration  # ì •í™•í•œ 3ì´ˆ ê°„ê²© ìœ ì§€

                except Exception as e:
                    print(f"âŒ ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e}")

        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë²„í¼ë§/ì €ì¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # return processed_frame
        return frame



    def _process_stt_results_sync(self):
        """íì—ì„œ STT ê²°ê³¼ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            while True:
                try:
                    # ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ íì—ì„œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                    result = self.stt_result_queue.get(block=False)
                    self._send_text_via_datachannel(result['text'], result['timestamp'])
                    self.stt_result_queue.task_done()
                except queue.Empty:
                    break  # íê°€ ë¹„ì–´ìˆìŒ
        except Exception as e:
            print(f"âŒ STT ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    

    def get_stats(self) -> dict:
        """
        ì²˜ë¦¬ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        @returns {dict} ì²˜ë¦¬ í†µê³„
        """
        stats = self.processing_stats.copy()
        if stats['processed_frames'] > 0:
            stats['avg_processing_time'] = (
                stats['processing_time'] / stats['processed_frames']
            )
        return stats
    
    def reset_stats(self):
        """
        ì²˜ë¦¬ í†µê³„ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        self.processing_stats = {
            'total_frames': 0,
            'processed_frames': 0,
            'processing_time': 0.0,
            'audio_level': 0.0
        }
    
    def set_data_channel(self, data_channel):
        """
        Data Channelì„ ì„¤ì •í•©ë‹ˆë‹¤.
        
        @param {RTCDataChannel} data_channel - ì„¤ì •í•  Data Channel
        """
        self.data_channel = data_channel
        print(f"ğŸ“¡ AudioProcessorì— Data Channel ì„¤ì •ë¨: {data_channel.label}")
        

    def _send_text_via_datachannel(self, text: str, timestamp: float):
        """
        Data Channelì„ í†µí•´ í…ìŠ¤íŠ¸ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
        
        @param {str} text - ì „ì†¡í•  í…ìŠ¤íŠ¸
        @param {float} timestamp - íƒ€ì„ìŠ¤íƒ¬í”„
        """
        if self.data_channel and self.data_channel.readyState == "open":
            try:
                # ìš•ì„¤ ë‹¨ì–´ ê°ì§€ ë° ì¹´í…Œê³ ë¦¬ í• ë‹¹
                curse_info = self._detect_curse_words(text)
                
                # ìš•ì„¤/ê¸ˆì§€ì–´ê°€ ê°ì§€ëœ ê²½ìš° -> STT ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ êµ¬ì„± -> Data Channelë¡œ ì „ì†¡
                if curse_info['detected']:
                    message = {
                        "type": "voice",
                        "category": curse_info['category'], # 'ìš•ì„¤-ìˆ˜ìœ„ ì¤‘ê°„' or 'ê¸ˆì§€ì–´'
                        "detail": curse_info['detail'], # 'ê°œìƒˆë¼'
                        "time": datetime.fromtimestamp(timestamp).strftime("%H:%M:%S"),
                    }
                    # JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì „ì†¡
                    json_message = json.dumps(message, ensure_ascii=False)
                    self.data_channel.send(json_message)
                    print(f"ğŸš¨ ìš•ì„¤/ê¸ˆì§€ì–´ ê°ì§€: {curse_info['category']} - {curse_info['detail']}")
                    print(f"ğŸ“¤ Data Channelë¡œ STT ê²°ê³¼ ì „ì†¡: {text}")
            except Exception as e:
                print(f"âŒ Data Channel ì „ì†¡ ì‹¤íŒ¨: {e}")
        else:
            print("âš ï¸ Data Channelì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•¨")


                
    def send_custom_message(self, message_type: str, data: dict):
        """
        Data Channelì„ í†µí•´ ì»¤ìŠ¤í…€ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
        
        @param {str} message_type - ë©”ì‹œì§€ íƒ€ì…
        @param {dict} data - ì „ì†¡í•  ë°ì´í„°
        """
        if self.data_channel and self.data_channel.readyState == "open":
            try:
                message = {
                    "type": message_type,
                    "data": data,
                    "timestamp": pytime.time(),
                    "source": "audio_processor"
                }
                message_json = json.dumps(message, ensure_ascii=False)
                self.data_channel.send(message_json)
                print(f"ğŸ“¤ Data Channelë¡œ ì»¤ìŠ¤í…€ ë©”ì‹œì§€ ì „ì†¡: {message_type}")
            except Exception as e:
                print(f"âŒ Data Channel ì „ì†¡ ì‹¤íŒ¨: {e}")
        else:
            print("âš ï¸ Data Channelì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•¨")
    
    def start_speech_recognition(self):
        """
        ìŒì„± ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ¤ AudioProcessor.start_speech_recognition() í˜¸ì¶œë¨")
        if self.speech_recognizer:
            self.speech_recognizer.start_recognition()
            print("âœ… AudioProcessor: ìŒì„± ì¸ì‹ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ AudioProcessor: speech_recognizerê°€ Noneì…ë‹ˆë‹¤!")
    
    def stop_speech_recognition(self):
        """
        ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.
        """
        if self.speech_recognizer:
            self.speech_recognizer.stop_recognition()
            final_result = self.speech_recognizer.get_final_result()
            if final_result:
                print(f"ìµœì¢… ì¸ì‹ ê²°ê³¼: {final_result}")
            print("ìŒì„± ì¸ì‹ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    

    def get_recognition_results(self) -> list:
        """
        ì¸ì‹ ê²°ê³¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        @returns {list} ì¸ì‹ ê²°ê³¼ ëª©ë¡
        """
        return self.recognition_results.copy()


    def _detect_curse_words(self, text: str) -> dict:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ìš•ì„¤ ë‹¨ì–´ë¥¼ ê°ì§€í•˜ê³  ì¹´í…Œê³ ë¦¬ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
        
        @param text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
        @returns: ìš•ì„¤ ê°ì§€ ì •ë³´ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬

        # í˜„ì¬ category_info êµ¬ì¡° (get_audio_filter ë°˜í™˜ê°’)
        {
            "profanity": "mid",
            "hateSpeech": false,
            "bannedWords": ["ë¹¨ë¦¬", "ëŠë ¤"]
        }
        """     
        try:
            # session_idê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì„¸ì…˜ì˜ í•„í„° ì„¤ì • í™•ì¸
            if self.session_id:
                category_info = session_state_manager.get_audio_filter(self.session_id)
                if category_info:
                    print(f"ğŸ”§ ì„¸ì…˜ {self.session_id} ì¹´í…Œê³ ë¦¬ ì •ë³´: {category_info}")

                    # âœ… ê¸ˆì§€ì–´ ê°ì§€ ì¶”ê°€
                    banned_words = category_info.get('bannedWords', []) # ê¸ˆì§€ì–´ ëª©ë¡ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
                    for banned_word in banned_words:
                        if banned_word in text.replace(' ', ''):
                            print(f"ğŸš¨ ê¸ˆì§€ì–´ ê°ì§€: {banned_word}")
                            return {
                                'detected': True,
                                'category': 'ê¸ˆì§€ì–´',
                                'detail': banned_word,
                            }
                    
                    # profanity ìˆ˜ìœ„ ë ˆë²¨ í™•ì¸
                    profanity_level = category_info.get('profanity')
                    if profanity_level:
                        print(f"ğŸ” ì„¸ì…˜ {self.session_id}: ìš•ì„¤ ìˆ˜ìœ„ ë ˆë²¨ - {profanity_level}")
                else:
                    print(f"âš ï¸ ì„¸ì…˜ {self.session_id}: ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ìŒ, ê¸°ë³¸ í•„í„°ë§ ì ìš©")
                    profanity_level = None
            else:
                print("âš ï¸ session_id ì—†ìŒ, ê¸°ë³¸ í•„í„°ë§ ì ìš©")
                profanity_level = None
            
            # profanity ìˆ˜ìœ„ì— ë”°ë¼ ê°ì§€í•  ì¹´í…Œê³ ë¦¬ ê²°ì •
            allowed_categories = PROFANITY_LEVEL_MAPPING.get(profanity_level, ['high', 'mid', 'low'])
            print(f"ğŸ” ê°ì§€ í—ˆìš© ì¹´í…Œê³ ë¦¬: {allowed_categories}")
            
            detected_words = []
            detected_category = None
            
            # í—ˆìš©ëœ ì¹´í…Œê³ ë¦¬ë§Œ ê²€ì‚¬
            for category in allowed_categories:
                if category in self.curse_words:
                    for word in self.curse_words[category]:  # curse_words[category]ë¡œ ìˆ˜ì •
                        if word in text:
                            detected_words.append({
                                'word': word,
                                'category': category
                            })
                            # ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ ì„ íƒ (high > mid > low)
                            if detected_category is None or PROFANITY_LEVEL_PRIORITY_MAP.get(category, 0) > PROFANITY_LEVEL_PRIORITY_MAP.get(detected_category, 0):
                                detected_category = category
            
            if detected_words:
                # ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„ì˜ ë‹¨ì–´ ì„ íƒ
                highest_priority_word = max(detected_words, key=lambda x: PROFANITY_LEVEL_PRIORITY_MAP.get(x['category'], 0))
                return {
                    'detected': True,
                    'category': CATEGORY_KOREAN_MAP.get(highest_priority_word['category'], 'ì•Œ ìˆ˜ ì—†ìŒ'),
                    'detail': highest_priority_word['word'],
                }
            else:
                return {
                    'detected': False,
                    'category': None,
                    'detail': None,
                }
                
        except Exception as e:
            print(f"âš ï¸ ìš•ì„¤ ë‹¨ì–´ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'detected': False,
                'category': None,
                'detail': None,
            }

       
    
    # def _get_category_priority(self, category: str) -> int:
    #     """
    #     ì¹´í…Œê³ ë¦¬ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
    #     @param category: ì¹´í…Œê³ ë¦¬ ('high', 'mid', 'low')
    #     @returns: ìš°ì„ ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    #     """
    #     priority_map = {
    #         'high': 3,
    #         'mid': 2,
    #         'low': 1
    #     }
    #     return priority_map.get(category, 0)
    
    # def _get_category_korean(self, category: str) -> str:
    #     """
    #     ì¹´í…Œê³ ë¦¬ë¥¼ í•œê¸€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
    #     @param category: ì¹´í…Œê³ ë¦¬ ('high', 'mid', 'low')
    #     @returns: í•œê¸€ ì¹´í…Œê³ ë¦¬
    #     """
    #     korean_map = {
    #         'high': 'ìš•ì„¤-ìˆ˜ìœ„ ë†’ìŒ',
    #         'mid': 'ìš•ì„¤-ìˆ˜ìœ„ ì¤‘ê°„',
    #         'low': 'ìš•ì„¤-ìˆ˜ìœ„ ë‚®ìŒ'
    #     }
    #     return korean_map.get(category, 'ì•Œ ìˆ˜ ì—†ìŒ')




    # def _get_allowed_categories_by_profanity_level(self, profanity_level: str) -> list:
    #     """
    #     profanity ìˆ˜ìœ„ ë ˆë²¨ì— ë”°ë¼ ê°ì§€í•  ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë°˜í™˜
        
    #     @param profanity_level: 'high', 'mid', 'low' ë˜ëŠ” None
    #     @returns: ê°ì§€í•  ì¹´í…Œê³ ë¦¬ ëª©ë¡
    #     """
    #     if not profanity_level:
    #         return ['high', 'mid', 'low']  # ê¸°ë³¸ê°’: ëª¨ë“  ì¹´í…Œê³ ë¦¬
        
    #     level_mapping = {
    #         'high': ['high', 'mid', 'low'], # high, mid, low ëª¨ë‘ ê°ì§€
    #         'mid': ['high', 'mid'],     # high, mid ê°ì§€
    #         'low': ['high'],  # highë§Œ ê°ì§€
    #     }
        
    #     return level_mapping.get(profanity_level, ['high', 'mid', 'low'])